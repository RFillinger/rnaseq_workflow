---
title: "RNAseq with EdgeR (Long Report)"
author: "Dean Pettinga"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
params:
  rmd: ""
output:
  html_document:
    self_contained: yes
    toc: true
    toc_depth: 5
    toc_float:
      collapsed: false
      smooth_scroll: true
    number_sections: false 
    df_print: paged
    theme: yeti
---
Tested in R version `r getRversion()`.

```{r setup,echo=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE,cache=TRUE)
```

```{r loadlibs}
#Check if packages can be loaded and download and install them if they are not found
cranPkgLoad <- function(x)
  {#General function to see if a CRAN package is installed and if not, to install it
    if (!require(x,character.only = TRUE))
    {
      #Install the given package and its dependencies through the user default CRAN mirror
      install.packages(x,dep=TRUE, repos="https://cloud.r-project.org/")
      #Throw an error and halt program execution if the package cannot be loaded or installed
      #There is likely an error with the mirror or package and inform the user to look at the software docs
      if(!require(x,character.only = TRUE)) stop("Tried to install the above CRAN package but could not. Refer to the documentation for additional details regarding manual installation.")
    }
  }

biocPkgLoad <- function(x)
  { #General function to see if a bioconductor package is installed and if not, to install it
    if (!require(x,character.only = TRUE))
    {
      #Check if the BiocInstaller library can be loaded
      if (!require(BiocManager))
      {
        #http was chosen here in case https is not supported
        source("http://bioconductor.org/BiocManager.R")
      }
      #Suppress any updates to the package or its dependencies and suppress updates to the bioconductor package manager
      #Install the bioconductor package and its dependencies through the user default bioc mirror
      BiocManager::install(x,suppressUpdates = TRUE, suppressAutoUpdate = TRUE)
      #Throw an error and halt program execution if the package cannot be loaded or installed
      #There is likely an error with the mirror or package and inform the user to look at the software docs
      if(!require(x,character.only = TRUE)) stop("Tried to install the above bioConductor package but could not. Refer to the documentation for additional details regarding manual installation.")
    }
}
library(ggplot2)
library(gplots)
library(biomaRt)
library(reshape2)
library(reshape)
library(gridExtra)
require(grid)
library(plyr)
library(dplyr)
library(tidyr)
library(ggrepel)
library(RColorBrewer)
library(goseq)
library(edgeR)
library(pheatmap)
#library(ggalt)
library(ggfortify)
library(kableExtra)
#library(formattable)
library(readxl)
library(UpSetR)
library(xtable)
#library(sva)
library(tibble)
library(msigdbr)
library(data.table)
library(fgsea)
library(statmod)
library(matrixStats)
```

```{r, RNAseq}

volcano = function(log2FC,pval,qval,fdr.filter,title){
  if(missing(title)){
    title=''
  }
  x = as.data.frame(cbind(log2FC,pval,qval))
  x$signif = ifelse(qval>fdr.filter,'Not Significant',
              ifelse((log2FC>0 & (abs(log2FC)>logfc.filter)),'Significant Upregulated',
                ifelse((log2FC<0 & (abs(log2FC)>logfc.filter)),'Significant Downregulated',
                  'Not Significant'
                )
              )
            )
  n.signif = length(which(x$signif%in%c('Significant Upregulated','Significant Downregulated')))
  plot = ggplot(x,aes(x=log2FC,y=-log10(pval))) + 
    geom_point(aes(color=signif)) + 
    # scale_colour_brewer(palette = 'Paired') +
    scale_colour_manual(values = c('Gray','Blue','Red')) +
    # geom_vline(xintercept = logfc.filter) +
    # geom_vline(xintercept = -logfc.filter) +
    # geom_hline(yintercept = -log(fdr.filter)) + 
    ggtitle(paste(title,'Volcano plot.',n.signif,'Significant Tags'))
  return(plot)
}

## For this function to work:

# Need a design matrix.
# Need a contrast matrix that works with the design.
# Need a predefined df called 'meta' with columns 'sample' and 'genotype'.
# Need a predefined logfc.filter, fdr.filter, and t2g_no_dup_genes.
# Need a Formal class 'DGEList' with the filtered count data (default to the filtered.data obj from the project Rmd)
RNAseq = function(design,contrast,.meta,block){
  
  # Check that filtered.data is a DGEList object!
  # if(class(filtered.data)!='DGEList'){
  #   stop('Error - filtered.data NOT a DGEList Object\n')
  # }
  
  cat('FDR Filter:',fdr.filter,'.\n\nlogFC Filter',logfc.filter,'.\n\n')
  # Format design
  rownames(design) <- .meta$sample # do not make these names, make meta names in 'load data' tab
  colnames(design)=make.names(colnames(design))
  # check if anything in the design is non-estimable:
  nonEstimable(design)
  
  # Print the design:
  print(
    knitr::kable(design,caption='Diff. Gene Expr. Analysis Design:') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)
  )
    # Save it as an object:
    saveRDS(
      knitr::kable(design,caption='Diff. Gene Expr. Analysis Design:') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12),
      paste0("r_objects/DGE_design.",contrast.name,".rds")
    )
  
  # Print the contrast matrix:
  print(
    knitr::kable(contrast,caption='Contrast Matrix:') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)
  )
    # Save it as an object:
    saveRDS(
      knitr::kable(contrast,caption='Contrast Matrix:') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12),
      paste0("r_objects/contrastMatrix.",contrast.name,".rds")
    )  
  
  ##Generate the DGEList object from the filtered data
  y <- filtered.data[,rownames(design)]
  
  #Normalize based on library size and composition biases in the sample - trimmed mean of M-values (TMM) method
  #The normalization factors of all the libraries multiply to unity. A normalization factor below one indicates that a small
  #number of high count genes are monopolizing the sequencing, causing the counts for other genes to be lower than
  #would be usual given the library size. As a result, the effective library size will be scaled down for that sample.
  cat('Normalizing for library size and composition biases in the samples using trimmed mean of M-values (TMM) method\n')
  y <- edgeR::calcNormFactors(y)
  
  #Check norm.factors:
  print(
    y$samples %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)
  )
  
  #Check MDS plot:
  cat('In the MDS plot, the distance between each pair of samples can be interpreted as the leading log-fold
change between the samples for the genes that best distinguish that pair of samples. By default, leading fold-change is defined as the root-mean-square of the largest 500 log2-fold changes between that pair of samples.\n'
  )
  plotMDS(y)
  
  #Calc dispersions
  y <- estimateDisp(y, design, robust = TRUE)
  
  #Check the dispersion estimates
  cat('\n\n')
  cat('Common dispersion:',y$common.dispersion,'.\n\n\n') 
  #The square root of dispersion is the common coefficient of biological variation (BCV):
  cat('Biological Coefficient of Variation:',sqrt(y$common.dispersion),'.\n\n\n')
  cat('Typical values for the common BCV (square-root-dispersion) for datasets arising from well-controlled experiments are 0.4 for human data, 0.1 for data on genetically identical model organisms or 0.01 for technical replicates.\n\n\n')
  
  #Plot the BCV dispersions
  plotBCV(y)
  
  
  # Duplicate correlations if e.g. blocking for random effects - not implemented in current version
  # if(! missing(block)){
  #   cor=duplicateCorrelation(y$counts,design,block=block)
  #   fit <- glmQLFit(y, design, robust=TRUE,block=block,correlation=cor$consensus.correlation) # fit is a DGEGLM object
  # }else{
  
  
  # Fit the model ####
    # The quasi-liklihood dispersions can be estimated using the glmQLFit function
  fit <- glmQLFit(y, design, robust=TRUE) # fit is a DGEGLM object
  # }
  
  #Plot the quasi-liklihood dispersions. 
  plotQLDisp(fit)
  
  # Differential expression testing
  # Default: glmQLFtest

  # method 1:
  #working if design ~genotype+covariates not ~0+genotype+covariates
  #The coef argument corresponds to the column in the design matrix
  #glmQLFTest(fit, coef = 1) # method 1 ()
  
  #method 2 (working if design ~0+genotype):
  #contrast1 = makeContrasts(genotypeOfInterest-genotypeControl,levels=design) # an example with 1 contrast
  
  # When you pass multiple coefficients or contrasts to glmQLFTest, it will do an ANOVA-like test of the combined null hypothesis that all of them are equal to zero.
  qlf <- glmQLFTest(fit, contrast = contrast)

  # Get topTags ####
  Table <- topTags(qlf, n = Inf, p.value =1)$table # Get all genes
  Table$ens_gene <- rownames(Table)
  Table = dplyr::left_join(Table,t2g_no_dup_genes,by='ens_gene')
  Table.filtered = dplyr::filter(Table,FDR<=fdr.filter) # Filtere on qval
  cat("\n\nTotal tags: ",nrow(Table),".\n")
  cat(paste0("\n\n\n\n\nTags with FDR<",fdr.filter,": ",nrow(Table.filtered)),".\n\n\n\n")
  # Because there can be multiple contrasts, need to filter on logFC in the following way:
  logfold.columns = grep('logFC',colnames(Table.filtered)) # get columns for logFC 
  if(length(logfold.columns)==1){  
    Table.filtered = Table.filtered[ifelse(lapply(Table.filtered[,logfold.columns],FUN=function(x){return(max(abs(x)))})>logfc.filter,TRUE,FALSE),]
  }else{
    Table.filtered = Table.filtered[ifelse(apply(Table.filtered[,logfold.columns],1,FUN=function(x){return(max(abs(x)))})>logfc.filter,TRUE,FALSE),]
  }
  cat(paste0("\n\n\n\n\nDifferentially expressed tags (FDR<",fdr.filter," & logFC>",round(logfc.filter,2),"): ",nrow(Table.filtered)),".\n\n\n\n")
  

  #Histogram of PValue for all genes
  print(
    ggplot(Table) + geom_histogram(aes(x=PValue),bins=100) + labs(title='PValue Distribution')
  )

  #Volcano Plot:
  for(i in logfold.columns){
    print(
      volcano(log2FC = Table[,i],pval=Table$PValue,qval=Table$FDR,fdr.filter = fdr.filter,title=colnames(Table)[i])
    )
    # save as object
    saveRDS(
      volcano(log2FC = Table[,i],pval=Table$PValue,qval=Table$FDR,fdr.filter = fdr.filter,title=colnames(Table)[i]),
      paste0("r_objects/volcano.",contrast.name,".rds")
    )
    cat('\n\n')
  }
  
  # Top DGE 
  topN=25
  print(
    head(Table,topN) %>% knitr::kable(caption=paste('Top',topN,'Differentially Expressed Genes By Adjusted Pvalue')) %>% 
      kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)
  )
  # Save as object
  saveRDS(
    head(Table,topN) %>% knitr::kable(caption=paste('Top',topN,'Differentially Expressed Genes By Adjusted Pvalue')) %>% 
      kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12),
    paste0("r_objects/topGenes.",contrast.name,".rds")
  )
  
  
  #Write out the table
  #write.table(Table, "Controls.dge.txt", quote = F, sep = "\t", row.names = F, col.names = T)
  
  returnList = list(
    table=Table,
    de.genes = Table.filtered$ens_gene
  )
  return(returnList)
  
  # Limma is the only package that has the ability to use random effects to correlate repeated 
  # samples from the same subject. None of the negative binomial packages, including edgeR, can do that.
}

# For this function, need:
#   t2g with transcript_length & ens_gene columns
#   genelist with significant genes only
#   genome: 
genesetenrichment = function(de.genelist,genelist,lengthData,goseq_mapper,reactome.mapper){
  names(lengthData) = genelist
  
  # Get gene vectors for the goseq pwf function (vector of all genes, 1 if DE, 0 if not DE)
  formatted.genelist=as.integer(genelist%in%de.genelist)
  
  # Probability Weighting Function to establish the null distribution for goseq
  # supportedGenomes()
  pwf=nullp(formatted.genelist,id="ens_gene",bias.data=lengthData,plot.fit=F)
  # plotPWF(pwf,main=paste('pwf fit')) # plot the pwf
  
  # Format pwf:
  rownames(pwf) = names(lengthData) 
  
  # Do goseq:
  GO = goseq(pwf,
             # gene2cat = dplyr::select(t2g,one_of(c('ens_gene','go_id'))), # A data frame with two columns containing the mapping between genes and the categories of interest
             gene2cat = goseq_mapper,
             test.cats = "KEGG" # "GO:CC", "GO:BP", "GO:MF" & "KEGG". The three GO terms refer to the Cellular Component, Biological Process and Molecular Function respectively. "KEGG" refers to KEGG pathways.
  )
  # GO=GO[-which(is.na(GO$ontology)),] # sometimes a few ontologies are NA
  # GOBP = subset(GO,GO$ontology=="BP")# Subset to GO:Biological Process (not done by goseq despite test.cats="GO:BP")
  
  # Get the signif over/under represented GO terms:
  overrep = which(p.adjust(GO$over_represented_pvalue,method="BH")<fdr.filter)
  underrep = which(p.adjust(GO$under_represented_pvalue,method="BH")<fdr.filter)

  
  if(!missing(reactome.mapper)){
    cat('Gene set enrichment with Reactome Pathways\n')
    cat('\nFound',length(overrep),'OVERREPRESENTED reactome pathways with an adjusted p.value <',fdr.filter,'\n\n')
    cat('\nFound',length(underrep),'UNDERREPRESENTED reactome pathways with an adjusted p.value <',fdr.filter,'\n\n') 
    if(length(overrep)>0){
      print(
        dplyr::left_join(
          GO[overrep,],reactome.mapper,
          by=c('category'='Reactome_Pathway')
        ) %>% knitr::kable(caption='Overrepresented Reactome Pathways') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)
      )
    }
    if(length(underrep)>0){
      print(
        dplyr::left_join(
          GO[underrep,],reactome.mapper,
          by=c('category'='Reactome_Pathway')
        ) %>% knitr::kable(caption='Underrepresented Reactome Pathways') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)
      )
    }
  }else{
    cat('\nGene set enrichment with GO terms\n')
    cat('\nFound',length(overrep),'OVERREPRESENTED ontology terms with an adjusted p.value <',fdr.filter,'\n\n')
    cat('\nFound',length(underrep),'UNDERREPRESENTED ontology terms with an adjusted p.value <',fdr.filter,'\n\n') 
    if(length(overrep)>0){
      # cat('#### Overrep\n')
      # Table of the frequency of GO ontology:
      print(
        as.data.frame(table(GO[overrep,]$ontology)) %>% dplyr::rename('ontology'='Var1') %>% 
          knitr::kable(caption='Ontology frequency for significantly OVERREPRESENTED GOs') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)
      )
      # Full table:
      print(
        knitr::kable(GO[overrep,],caption='Overrepresented Gene Ontologies') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)
      )
      }
    if(length(underrep)>0){
      if( ! is.na(GO[underrep,]$ontology)){
        # cat('#### Underrep\n')
        # Table of the frequency of GO ontology:
        print(
          as.data.frame(table(GO[underrep,]$ontology)) %>% dplyr::rename('ontology'='Var1')  %>% knitr::kable(caption='Ontology frequency for significantly UNDERREPRESENTED GOs') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)
        )
        # Full table:
        print(
          knitr::kable(GO[underrep,],caption='Underrepresented Gene Ontologies') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)
        )
      }
    }
 
  }
  #_________________________________________________________________________________
  # Get the genes that are in the overepresented BP GOs
  # go2get = GO[overrep,1]
  # First get the genes that have that have overrep GO & are signif DE
  # genes = t2g[which(t2g$go_id %in% go2get & t2g$ensembl_gene_id %in% vector),1] # ens_gene for genes with go2get
  # DEtags_withGO = dplyr::filter(t2g,ens_gene %in% genes & go_id %in% go2get)
  #_________________________________________________________________________________
  #Print the tables:
  
  # knitr::kable(DEtags_withGO,caption=paste0('DE genes with a GO in the overrepresented GO terms'))
  # knitr::kable(GOBP[underrep,],caption='Underrepresented biological processes') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)

}

gsea_output_files = function(samples,genotypes,file.prefix,exprdata,t2g_no_dup_genes){

  # Write the genelist to a .gmx file 
  # gmx = 'NAME OF GENE LIST.gmx'
  # cat("NAME OF GENE LIST\n",file=gmx)
  # cat("na\n",file=gmx,append=TRUE)
  # cat(genelist,sep="\n",file=gmx,append=TRUE)
  
  # phenotype .cls
  filepheno<-paste0("../deliverables/",file.prefix,".cls")
  cat(c(length(samples),length(unique(genotypes)),1),file=filepheno,sep=' ')
  cat("\n",file=filepheno,append = TRUE)
  cat('#',unique(as.character(genotypes)),file=filepheno,sep=" ",append = TRUE)
  cat("\n",file=filepheno,append = TRUE)
  cat(as.character(genotypes),file=filepheno,sep=" ",append = TRUE)
  cat("\n",file=filepheno,append = TRUE)
  
  # .gct
  exprdata = exprdata[,which(colnames(exprdata) %in% samples)]
  exprdata = exprdata[,as.character(samples)]
  # get ext_gene
  mapper = as.data.frame(rownames(exprdata)); colnames(mapper)='ens_gene'
  mapper = dplyr::left_join(mapper,dplyr::select(t2g_no_dup_genes,one_of(c('ens_gene','ext_gene'))),by='ens_gene')
  NAME=toupper(mapper$ext_gene)
  # exprdata = exprdata[duplicated(fulltumd$ext_gene)==FALSE,]
  DESCRIPTION = rep('NA',nrow(exprdata))
  exprdatafile = paste0("../deliverables/",file.prefix,'.gct')
  cat('# 1.2',file=exprdatafile)
  cat("\n",file=exprdatafile,append = TRUE)
  # cat(nrow(exprdata),"\t",ncol(exprdata),file=exprdatafile,append=TRUE)
  cat(paste0(nrow(y.voom$E),"\t",ncol(y.voom$E)),file=exprdatafile,append=TRUE)
  cat("\n",file=exprdatafile,append = TRUE)
  exprdata = as.data.frame(cbind(NAME,DESCRIPTION,exprdata)) # Total data formatted
  write.table(exprdata,exprdatafile,sep="\t",row.names = FALSE,quote = FALSE,append=TRUE)
  
  # length(which(raw.list$ext_gene %in% rownames(exprdata)))
  #chip file
  chipfile = paste0("../deliverables/",file.prefix,'.chip')
  chip = t2g_no_dup_genes %>% 
                filter(ens_gene %in% rownames(y.voom$E)) %>% 
                select(ext_gene,ens_gene,predicted_function) %>% 
                rename("Probe Set ID"= ext_gene,"Gene Symbol"=ens_gene,"Gene Title"=predicted_function)
              
  write.table(chip,chipfile, sep="\t",row.names = FALSE,quote = FALSE,append=TRUE)
  
  
  # Report the output files
  cat('Files for GSEA:\n')
  
  cat('\t',filepheno,'\n\t',exprdatafile,'\n')
}

feature_counts_and_low_count_filtering = function(raw_data,sample.cpm.filter,cpm.filter){
  
  # Library sizes are computed from the reads counts for mapped reads to gff features
  lib_sizes <- data.frame(colSums(raw_data)/1e6) # In millions
  lib_sizes$sample <- factor(rownames(lib_sizes))
  colnames(lib_sizes)[1] <- 'millions_of_counts'
  
  cat('Raw Feature Counts Summary (Millions):\n')
  # print(
    # t(summary(lib_sizes$millions_of_counts)) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)
  # )
  print(
    as.matrix(summary(lib_sizes$millions_of_counts)) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)
  )
  print(
    knitr::kable(lib_sizes,caption='Raw Feature Counts') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)
  )
  print(
    ggplot(lib_sizes, aes(x = sample, y = millions_of_counts)) +
      geom_bar(stat="identity",fill='blue') +
      labs(caption=paste0('data: ',raw.data.file),y="Raw Counts (Millions)",title="Total Raw Read Counts For All Features") +
      theme_bw(10) +
      theme(
        axis.text.x = element_text(angle=45, hjust=1),
        axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5)
      )
  )
  
  
  raw.data.dgelist <- DGEList(counts=raw_data)
  rd = tidyr::gather(as.data.frame(raw.data.dgelist$counts),sample,count) 
  rd = dplyr::left_join(rd,meta)
  
  cat("Total tags:",nrow(raw_data),'\n')
  cat("Total tags with >0 counts:",nrow(raw_data[rowSums(raw_data) >= 1,]),'\n')
  
  plot = ggplot(rd,aes(x=sample, y=count, fill=genotype)) +
    geom_boxplot() +
    scale_fill_brewer(palette = "Set1") +
    ylab("Counts Per Million") +
    ggtitle("Raw Untransformed Count Distributions") +
    theme_bw() +
    theme(
      plot.margin = margin(2, 2, 2, 2, "cm"),
      axis.text.x = element_text(angle=45, hjust=1,size=12),
      axis.title.x = element_blank(),
      plot.title = element_text(hjust = 0.5)
    ) 
  print(
    plot 
  )
  print(
    plot + ylim(c(0,as.numeric(quantile(rd$count,probs=c(0.9))))) + ggtitle('Raw Untransformed Count Distributions - ylim=c(0,90th quantile)') # ylim to 90% 
  )
  print(
    rd %>% ggplot(aes(count)) + geom_histogram(binwidth=1) + ggtitle('Raw Data Gene Count Histogram') + xlim(c(0,as.numeric(quantile(rd$count,probs=c(0.9)))))
  )
  
  # Filter 1
  # 
  if(missing(sample.cpm.filter)){sample.cpm.filter=2} # How many samples must meet the cpm threshhold
  if(missing(cpm.filter)){
    cpm.filter=10/min(lib_sizes$millions_of_counts) # feature cpm threshold
  }
  cat('The cpm filter is derived from a minimum of 10 counts in the smallest library (In this case,',min(lib_sizes$millions_of_counts),'million counts in sample',as.character(lib_sizes$sample[which.min(lib_sizes$millions_of_counts)]),')\n')
  cat('In this case, for a gene to pass filtering, need ≥',cpm.filter,'cpm in ≥',sample.cpm.filter,'samples\n')
  keep <- rowSums(cpm(raw.data.dgelist)>cpm.filter) >= sample.cpm.filter
  filtered.data <- raw.data.dgelist[keep, , keep.lib.sizes=FALSE]
  cat(nrow(filtered.data$counts),"genes PASS this filter.\n")
  
  fd = tidyr::gather(as.data.frame(filtered.data$counts),sample,count) 
  fd = dplyr::left_join(fd,meta)
  
  plot = fd %>% ggplot(aes(count)) + geom_histogram(binwidth=1) + ggtitle('Filtered Data Gene Count Histogram') + xlim(c(0,as.numeric(quantile(fd$count,probs=c(0.9)))))
  print(
    plot
  )
  print(
    plot + xlim(0,as.numeric(quantile(fd$count,probs=c(0.25)))) + ggtitle('Filtered Data Gene Count Histogram - xlim=c(0,25th quantile)')
  )
  
  
  
  plot = ggplot(fd,aes(x=sample, y=count, fill=genotype)) +
    geom_boxplot() +
    scale_fill_brewer(palette = "Set1") +
    ylab("Counts Per Million") +
    ggtitle(paste0("Filtered Untransformed Count Distributions - ",nrow(filtered.data$counts)," Tags")) +
    theme_bw() +
    theme(
      plot.margin = margin(2, 2, 2, 2, "cm"),
      axis.text.x = element_text(angle=45, hjust=1,size=12),
      axis.title.x = element_blank(),
      plot.title = element_text(hjust = 0.5)
    ) + ylim(c(0,as.numeric(quantile(fd$count,probs=c(0.9))))) # ylim to 90% 
  print(
    plot
  )
  
  return(filtered.data)
  
}
 

```

```{r t2g_object,eval=TRUE,cache=TRUE}
# Set the host:
# mart <- biomaRt::useMart(biomart = 'ENSEMBL_MART_ENSEMBL',dataset = 'hsapeins_ensembl')
# View(listDatasets(mart))
# View(listAttributes(mart,))

if (!exists(c("t2g_no_dup_genes","t2g"))){
  t2g_file='r_objects/ensembl_go.rds'
  if(t2g_file %in% list.files()){
    t2g = readRDS(t2g_file)
  }else{
    mart <- biomaRt::useMart(biomart = 'ENSEMBL_MART_ENSEMBL', host="www.ensembl.org", dataset = 'hsapiens_gene_ensembl', ensemblRedirect = NULL)
    t2g_1 <- biomaRt::getBM(attributes = c("ensembl_gene_id", "external_gene_name"), mart = mart)
    t2g_2 <- biomaRt::getBM(attributes = c("ensembl_gene_id", "description"), mart = mart)
    t2g_3 <- biomaRt::getBM(attributes = c("ensembl_gene_id", "chromosome_name"), mart = mart)    
    t2g_4 <- biomaRt::getBM(attributes = c("ensembl_gene_id", "start_position"), mart = mart)
    t2g_5 <- biomaRt::getBM(attributes = c("ensembl_gene_id", "end_position"), mart = mart)
    t2g_6 <- biomaRt::getBM(attributes = c("ensembl_gene_id", "transcript_length"), mart = mart)
    t2g_7 <- biomaRt::getBM(attributes = c("ensembl_gene_id", "go_id"), mart = mart)
    
    t2g <- t2g_1 %>%
      left_join(t2g_2, by='ensembl_gene_id') %>%
      left_join(t2g_3, by='ensembl_gene_id') %>%
      left_join(t2g_4, by='ensembl_gene_id') %>%
      left_join(t2g_5, by='ensembl_gene_id') %>%
      left_join(t2g_6, by='ensembl_gene_id') %>%
      left_join(t2g_7, by='ensembl_gene_id') %>%
      dplyr::rename(ens_gene = ensembl_gene_id, ext_gene = external_gene_name, predicted_function = description)
    
    saveRDS(t2g, file=t2g_file)
  }
  t2g_no_dup_genes = t2g[-which(duplicated(t2g$ens_gene)),-which(colnames(t2g)=='go_id')] # no duplicates (e.g. when multipe mappings to go terms)
}
```

```{r load_REACTOME_db}

reactome.mapper = read.delim('https://reactome.org/download/current/Ensembl2Reactome_All_Levels.txt',sep='\t',header=FALSE)

colnames(reactome.mapper)=c('ens_gene','Reactome_Pathway','url','Pathway_Name','Evidence_Code','Species')
reactome.mapper = dplyr::filter(reactome.mapper,Species=='Homo sapiens')
reactome.mapper$ens_gene=as.character(reactome.mapper$ens_gene)
# dim(reactome.mapper)
# length(unique(reactome.mapper$ens_gene))
#    Source database identifier, e.g. UniProt, ENSEMBL, NCBI Gene or ChEBI identifier
#    Reactome Pathway Stable identifier
#    URL
#    Event (Pathway or Reaction) Name
#    Evidence Code
#    Species
reactome.mapper.goseq = dplyr::select(reactome.mapper,one_of(c('ens_gene','Reactome_Pathway')))

# Now get the unique pathways:
reactome.mapper = dplyr::select(
  reactome.mapper[-which(duplicated(reactome.mapper$Reactome_Pathway)),],
  one_of(c('Reactome_Pathway','Pathway_Name'))
)

# # save the objects as RDS for later access
# saveRDS(reactome.mapper,"r_objects/reactome.mapper.RDS")
# saveRDS(reactome.mapper.goseq,"r_objects/reactome.mapper.goseq.RDS")

```

```{r define_fGSEA_functions, include=FALSE}

library(tibble)
getranks = function(title, table){

# calculate rankings
# use inverse sign of log change so that upregulated genes are at the left of the plots
table$FCsign <- sign(table$logFC)
table$logP <- -log10(table$FDR)
table$metric <- table$logP/table$FCsign

# set up the list of ranks for genes in order of the calculated metric
ranks <- table[,c("ext_gene","metric")]
ranks[,"ext_gene"] <- as.character(ranks[,"ext_gene"])

# remove samples with duplicate gene symbols, metrics, and NAs, NaNs for "metric"
# sort by metric: positive values first.
ranks <- dplyr::distinct(.data = ranks, ext_gene, .keep_all=TRUE) %>%
  dplyr::filter( !is.na(ext_gene)) %>% 
  arrange(-metric)
# convert NaN's to 0
ranks$metric[ranks$metric == "NaN"] <- 0
ranks$metric[ranks$metric == "Inf"] <- 0

# format frame for fgsea
ranks <- deframe(ranks)
}
```

# Intro 

## Methods

Raw data were quality controlled with FastQC. The reads have high quality for all samples. Adapters were removed with Trimgalore and mapped with STAR[1] to the **hg38 genome**. STAR outputs counts for all genomic features/tags/genes (option: --quantMode GeneCounts). These are the raw data imported into this R pipeline which uses the edgeR[2] framework for RNAseq analysis (see tab 'DGE Analysis' for more details). First, however, genes with low counts and unlikely to be translated (biologically meaningful) and also without enough counts for a reliable statistical judgement are removed. We require genes to have greater than (10/minimum sample library size in millions) counts per million in two samples.

**Programs**:

  + FastQC v0.11.5
  + multiqc v1.4 (http://multiqc.info/docs/)
  + Trimgalore v0.4.4_dev (https://www.bioinformatics.babraham.ac.uk/projects/trim_galore/)
  + STAR v2.5.2b

**Citations**:

 + [1] Dobin, A., Davis, C. A., Schlesinger, F., Drenkow, J., Zaleski, C., Jha, S., … Gingeras, T. R. (2013). STAR: Ultrafast universal RNA-seq aligner. Bioinformatics, 29(1), 15–21. https://doi.org/10.1093/bioinformatics/bts635
 + [2] Robinson, M. D., McCarthy, D. J., & Smyth, G. K. (2010). edgeR: a Bioconductor package for differential expression analysis of digital gene expression data. Bioinformatics (Oxford, England), 26(1), 139–140. https://doi.org/10.1093/bioinformatics/btp616

## Load Data

```{r load_metadata}

cat('This data powers the contrasts, if there are problems please contact me\n')
metadata.file="samples.tsv"
meta = read.delim(metadata.file,sep='\t',stringsAsFactors = TRUE,header=TRUE)
meta$sample = as.character(meta$sample)

cat('Found',nrow(meta),'samples in file',metadata.file,'\n')

table(meta$condition) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)

knitr::kable(dplyr::arrange(meta,condition),caption='Metadata') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)


# Build a model with all covariates & check if it is estimable:

# test.design = model.matrix(~0 + meta$treatment + meta$genotype)

# limma::nonEstimable(test.design)

# library(PerformanceAnalytics)
# chart.Correlation(meta)


```

```{r set_initial_RNAseq_filters}
fdr.filter=0.05
logfc.filter=1.5
```

```{r load_STAR_data}
# Load STAR feature counts:
raw.data.file='../deliverables/starMatrix.txt'
raw_data = read.delim(raw.data.file, row.names=1,stringsAsFactors = F, check.names = F,sep='\t')
raw_data <- raw_data[,-ncol(raw_data)] #Removing a column of NAs presuming it's the last column
cat('The following samples have no meta data:\n')
no.meta.data = colnames(raw_data)[which(! colnames(raw_data) %in% meta$sample)]
with.meta.data = colnames(raw_data)[which(colnames(raw_data) %in% meta$sample)]
cat(paste(no.meta.data,collapse = '\n'))
cat('\nThe following samples have no count data:\n')
no.raw.data = meta$sample[which(! meta$sample %in% colnames(raw_data))]
cat(paste(no.raw.data,collapse = '\n'))

rownames(raw_data)=gsub(x=rownames(raw_data),pattern ='\\.\\d{1,2}',replacement='',perl=TRUE) # remove

cat('Resolving...\n')
raw_data = raw_data[,with.meta.data]
if(length(no.raw.data)>0){
  meta[-which(meta$sample %in% no.raw.data),]
}

```

```{r mapping_stats_RNAseq,eval=FALSE}

# For usage with this bash code:
# if [ ! -f ${DIR}/deliverables/UniquelyMappingRates.txt ]; then
# echo "Generating Mapstats"
# echo "sample	UniquelyMappingRates" > ${DIR}/deliverables/UniquelyMappingRates.txt
# echo "sample	UniquelyMappingReads" > ${DIR}/deliverables/UniquelyMappingReads.txt
# grep 'Uniquely mapped reads %' ${ANALYSIS}*Log.final.out |cut -d ' ' -f1,29|awk -F 'Log.final.out: \\|' '{print $1$2}' >> ${DIR}/deliverables/UniquelyMappingRates.txt
# grep 'Uniquely mapped reads number' ${ANALYSIS}*Log.final.out |cut -d ' ' -f1,24|awk -F 'Log.final.out: \\|' '{print $1$2}' >> ${DIR}/deliverables/UniquelyMappingReads.txt
# fi
  mapstat = read.delim("../deliverables/UniquelyMappingRates.txt",sep='\t',header=TRUE,stringsAsFactors = F)
  colnames(mapstat)=c('sample','UniquelyMappingRate')
  mapstat$sample= gsub(".*/","",mapstat$sample)
  mapstat$UniquelyMappingRate=as.numeric(gsub('%','',mapstat$UniquelyMappingRate))
  # mapstat$sample= as.character(mapstat$sample)
  mapstat = dplyr::left_join(mapstat,meta)
  mapstat$sample=factor(mapstat$sample,levels=meta$sample)


  ggplot(mapstat,aes(x=sample,y=UniquelyMappingRate)) + 
    labs(title=paste('Mapping Stats - Uniquely Mapping Percentage'),subtitle='',caption='Data: UniquelyMappingRates.txt') +
    scale_color_brewer('Set1') + 
    ylim(0,100) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1,size=8)) + 
    geom_bar(stat="identity",position='stack') + labs(y='Uniquely Mapping Percentage',x='Sample') #+
    facet_grid(genotype~.)


mapstat = read.delim("../deliverables/UniquelyMappingReads.txt",sep='\t',header=TRUE,stringsAsFactors = F)
colnames(mapstat)=c('sample','UniquelyMappingReads')
mapstat$sample=gsub(".*/","",mapstat$sample)
mapstat = dplyr::left_join(mapstat,meta)
mapstat$sample=factor(mapstat$sample,levels=meta$sample)

# ggplot(mapstat,aes(UniquelyMappingReads)) + geom_histogram() #+ facet_grid(genotype~.)

ggplot(mapstat,aes(x=sample,y=UniquelyMappingReads)) + 
    labs(title=paste('Mapping Stats - Uniquely Mapping Reads'),subtitle='',caption='Data: UniquelyMappingReads.txt') +
    scale_color_brewer('Set1') + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1,size=8)) + 
    geom_bar(stat="identity",position='stack') + labs(y='Uniquely Mapping Reads', x='Sample') #+
    # facet_grid(genotype~.)

```

```{r raw_counts}

# Print the star raw counts with ext_gene
raw_data.ext = raw_data
raw_data.ext$ens_gene = rownames(raw_data.ext)
raw_data.ext = dplyr::left_join(raw_data.ext,
                    dplyr::select(t2g_no_dup_genes,one_of(c('ens_gene','ext_gene'))),
                                              by='ens_gene'
                    )
raw_data.ext = raw_data.ext[,c(
                                  which(colnames(raw_data.ext)%in%c('ens_gene','ext_gene')),
                                  which(! colnames(raw_data.ext)%in%c('ens_gene','ext_gene'))
                             )
                            ]
write.table(raw_data.ext, "../deliverables/STAR_raw_counts_with_annotation.txt", quote = F, sep = "\t", row.names = F, col.names = T)

```

# Differential Gene Expression 

## Feature Counts And Initial Filtering

```{r feature_counts_and_low_count_filtering}

# Library sizes are computed from the reads counts for mapped reads to gff features
lib_sizes <- data.frame(colSums(raw_data)/1e6) # In millions
lib_sizes$sample <- factor(rownames(lib_sizes))
colnames(lib_sizes)[1] <- 'millions_of_counts'

cat('Raw Feature Counts Summary (Millions):\n')
summary(lib_sizes$millions_of_counts)

knitr::kable(lib_sizes,caption='Raw Feature Counts') %>% kable_styling(bootstrap_options = c("striped", "hover","condensed"),font_size = 12)

ggplot(lib_sizes, aes(x = sample, y = millions_of_counts)) +
  geom_bar(stat="identity",fill='blue') +
  labs(caption=paste0('data: ',raw.data.file),y="Raw Counts (Millions)",title="Total Raw Read Counts For All Features") +
  theme_bw(10) +
  theme(
    axis.text.x = element_text(angle=45, hjust=1),
    axis.title.x = element_blank(),
    plot.title = element_text(hjust = 0.5)
  )

cat("Total tags:\n",nrow(raw_data))
raw.data.dgelist <- DGEList(counts=raw_data)
rd = tidyr::gather(as.data.frame(raw.data.dgelist$counts),sample,count) 
rd = dplyr::left_join(rd,meta)

cat("Total tags with >0 counts:\n",nrow(raw_data[rowSums(raw_data) >= 1,]))
plot = ggplot(rd, aes(x=sample, y=count, fill=condition)) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Set1") +
  ylab("Counts Per Million") +
  ggtitle("Raw Untransformed Count Distributions") +
  theme_bw() +
  theme(
    plot.margin = margin(2, 2, 2, 2, "cm"),
    axis.text.x = element_text(angle=45, hjust=1,size=12),
    axis.title.x = element_blank(),
    plot.title = element_text(hjust = 0.5))

plot + ylim(c(0,as.numeric(quantile(rd$count,probs=c(0.9))))) + ggtitle('Raw Untransformed Count Distributions - ylim=c(0,90th quantile)') # ylim to 90% 

rd %>% ggplot(aes(count)) + geom_histogram(binwidth=1) + ggtitle('Raw Data Gene Count Histogram') + xlim(c(0,as.numeric(quantile(rd$count,probs=c(0.9)))))

############################################################################
# Filter 1
# 
sample.cpm.filter = min(plyr::count(meta$group)$freq) # How many samples must meet the cpm threshhold (# of samples in smallest group)
cpm.filter = 10/min(lib_sizes$millions_of_counts) # feature cpm threshold
cat('Derived the cpm filter from a minimum of 10 counts in the smallest library\n')
cat('Filters:\nminimum',cpm.filter,'cpm in ',sample.cpm.filter,'sample\n')
keep <- rowSums(cpm(raw.data.dgelist)>cpm.filter) >= sample.cpm.filter
filtered.data <- raw.data.dgelist[keep, , keep.lib.sizes=FALSE]
cat("Filtered tags:\n",nrow(filtered.data$counts))

fd = tidyr::gather(as.data.frame(filtered.data$counts),sample,count) 
fd = dplyr::left_join(fd,meta)

plot = fd %>% ggplot(aes(count)) + geom_histogram(binwidth=1) + ggtitle('Filtered Data Gene Count Histogram') + xlim(c(0,as.numeric(quantile(fd$count,probs=c(0.9)))))
plot
plot + xlim(0,as.numeric(quantile(fd$count,probs=c(0.25)))) + ggtitle('Filtered Data Gene Count Histogram - xlim=c(0,25th quantile)')

plot = ggplot(fd,aes(x=sample, y=count, fill=condition)) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Set1") +
  ylab("Counts Per Million") +
  ggtitle(paste0("Filtered Untransformed Count Distributions - ",nrow(filtered.data$counts)," Tags")) +
  theme_bw() +
  theme(
    plot.margin = margin(2, 2, 2, 2, "cm"),
    axis.text.x = element_text(angle=45, hjust=1,size=12),
    axis.title.x = element_blank(),
    plot.title = element_text(hjust = 0.5)
  ) + ylim(c(0,as.numeric(quantile(fd$count,probs=c(0.9))))) # ylim to 90% 
plot
 


# Following feature counts, filtered.data is a DGEList object with the filtered genes.

```

## VOOM Normalization For Plotting

We use a VOOM normalization to visualize the data. This transforms on a log2 scale.

Publication describing VOOM: Law, C. W., Chen, Y., Shi, W., & Smyth, G. K. (2014). Voom: Precision weights unlock linear model analysis tools for RNA-seq read counts. Genome Biology, 15(2), 1–17. https://doi.org/10.1186/gb-2014-15-2-r29

```{r voom_normalization}
#Adjust for library size differences
#This isn't always necessary
filtered.data <- calcNormFactors(filtered.data)

# Rename the DGEList samples based on the genotype
#x$samples$group = meta$genotype 

# Covariates in the model:
# (e.g. covariate <- as.factor(meta$covariate)
#Or you can build up another variable factor list for other covariates to pass to the model
# covariate <- factor(c(rep(c( ... ), ... )))

# y <- voomWithQualityWeights(x, design) # useful if you are comparing a gene deletion to a control
design = model.matrix(~0 + condition, data = meta)
y.voom <- voom(filtered.data, design) # x is our DGEList counts data

# corfit <- duplicateCorrelation(y, design, block=c(meta$batch)) # duplicate
# y <- voom(x, design, block=meta$batch, correlation=corfit$consensus) # https://support.bioconductor.org/p/62631/

#Transpose the expression matrix
# the $E component of the output object contains a "numeric matrix of normalized expression values on the log2 scale".
v2 <- as.data.frame(t(y.voom$E))
# annotate samples from rows
v2$sample <- rownames(v2)
# add the condition by looking it up in meta matching the order of the v2$sample column.
v2$condition <- (dplyr::full_join(v2 %>% select(c("sample")),
                 meta %>% select(c("sample","condition")),
                 by="sample"))$condition


# v2$covariate <- meta$covariate
#If you have additional covariates, you'll need to add them as additional strings in the vector
#e.g. melted <- melt(v2, id.var=c("Sample", "Genotype", "COVARIATE"))
#e.g. colnames(melted) <- c("Sample", "Genotype", "COVARIATE", "Gene", "value")
melted <- melt(v2, id.var=c("sample", "condition"))
colnames(melted) <- c("sample", "condition", "gene", "value")


melted %>% ggplot(aes(value)) + geom_histogram(binwidth=1) + ggtitle('VOOM Transformed Filtered Data Gene Count Histogram') #+ xlim(c(0,as.numeric(quantile(melted$value,probs=c(0.9)))))


# Plot transformed count distributions
ggplot(melted, aes(x=sample, y=value, fill=condition)) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Set1") +
  ylab("log2 VOOM Transformed Counts Per Million") +
  ggtitle("Voom Transformed Filtered Data Count Distributions") +
  theme_bw() +
  theme(
    plot.margin = margin(2, 2, 2, 2, "cm"),
    axis.text.x = element_text(angle=45, hjust=1,size=12),
    axis.title.x = element_blank(),
    plot.title = element_text(hjust = 0.5)
  ) 

# write table of the CPM of each sample
write.table(cpm(filtered.data$counts), "../deliverables/cpm.txt", sep = "\t", row.names = T,col.names = NA)

# write table of the FPKM of each sample.
fpkm_table <- as.data.frame(filtered.data$counts)
fpkm_table$ens_gene <- rownames(fpkm_table)
t_lengths = dplyr::left_join(fpkm_table,
               t2g_no_dup_genes,
               by = 'ens_gene'
               ) %>%
  select(c("ens_gene","transcript_length"))

write.table(rpkm(filtered.data$counts,
                 gene.length = t_lengths$transcript_length,
                 normalized.lib.sizes = TRUE,
                 log = FALSE),
            "../deliverables/fpkm.txt",
            sep = "\t",
            row.names = T,
            col.names = NA)
```

## Sample Clustering 

### PCA

```{r PCA, fig.height=18,fig.width=18}
##Plot the PCA of genotype specific effects
# pca <- prcomp(t(filtered.data$counts)) # not normalized
pca <- prcomp(t(y.voom$E)) # voom normalized
pr_comps <- data.frame(pca$x)
pr_comps$sample <- rownames(pr_comps)
# add the condition by looking it up in meta matching the order of the v2$sample column.
pr_comps$condition <- (dplyr::full_join(v2 %>% select(c("sample")),
                 meta %>% select(c("sample","condition")),
                 by="sample"))$condition

pca_plot <- ggplot(pr_comps, aes(x=PC1, y=PC2)) + 
  geom_point(size=7,aes(color = condition, pch = condition)) + 
  theme_bw(10) + 
  scale_color_brewer(palette = 'Set1') + 
  geom_label_repel(aes(label=sample),show.legend = FALSE) #labels for individual datapoints

# Plot percent variation explained
prop_var <- data.frame(t(summary(pca)$importance))
names(prop_var) = c('sd', 'prop', 'cum')
prop_var$num = 1:nrow(prop_var)

var_plot <- ggplot(prop_var, aes(x=num, y=prop)) + 
  geom_point(size=1.5) + 
  geom_line() + 
  scale_x_continuous(limits = c(1, 12), breaks = 1:12) +
  xlab("Principal Component") + 
  ylab("Prop. of Variance") +
  ggtitle("PCA Plot of Expression Profiling") +
  theme_bw(10) +
  theme(
    axis.title.y = element_text(vjust=1),
    plot.margin = unit(c(0,0,0,6), "mm")
  ) 
vplayout <- function(x, y) viewport(layout.pos.row = x, layout.pos.col = y)

grid.newpage()
pushViewport(viewport(layout = grid.layout(4, 100)))
print(pca_plot, vp = vplayout(1:3, 3:100))
print(var_plot, vp = vplayout(4, 1:83))

#export image
# tiff("~/Desktop/PCA.tiff", height = 12, width = 17, units = 'cm', res = 300)
# pca_plot
# dev.off()

saveRDS(pca_plot, file = "r_objects/pca_plot.rds")
saveRDS(var_plot, file = "r_objects/var_plot.rds")

```


### Heatmap

```{r Heatmap_top_variable_genes,fig.height=28,fig.width=28}

topRows=100
# mat = log2(filtered.data$counts[order(rowMeans(y.voom$E),decreasing=TRUE)[1:topRows],]) # Mean
mat = y.voom$E[order(rowVars(y.voom$E),decreasing=TRUE)[1:topRows],] # Variance,

# -Inf if 0 on log2
mat[mat==-Inf] <- 0
saveRDS(mat, file = "r_objects/mat.rds")

# get the exterior gene names from the t2g object 
geneNames = t2g_no_dup_genes$ext_gene[which(t2g_no_dup_genes$ens_gene %in% rownames(mat))]
ensNames = t2g_no_dup_genes$ens_gene[which(t2g_no_dup_genes$ens_gene %in% rownames(mat))]
rowNames = cbind(geneNames,ensNames)
rowNames = rowNames[match(rownames(mat),rowNames[,2]),] # now in the right order
rowNames$use = paste(rowNames[,1],': ',rowNames[,2],sep='')
saveRDS(rowNames$use, file = "r_objects/rowNames_use.rds")


filtered.meta.heatmap <- as.data.frame(meta[,'condition']) # can take specific metadata: [,c("cov","geno")], but need two columns minimum
rownames(filtered.meta.heatmap) = meta$sample
saveRDS(filtered.meta.heatmap, file = "r_objects/filtered_meta_heatmap.rds")

heatmap = pheatmap(mat, cluster_rows=TRUE,
         labels_row = rowNames$use,
         show_rownames=TRUE,
         main=paste('Top 100 tags by expression variance',sep=''),
         cluster_cols=TRUE,
         annotation_col= as.data.frame(filtered.meta.heatmap) # requires a df
)


# export image (run through console)
# tiff("~/Desktop/Heatmap.tiff", width = 16, height = 16, units = 'in', res = 100, pointsize=1)
# pheatmap(mat, cluster_rows=TRUE,
#          labels_row = rowNames$use,
#          show_rownames=TRUE,
#          main=paste('Top 100 tags by expression variance',sep=''),
#          cluster_cols=TRUE,
#          annotation_col= as.data.frame(filtered.meta.heatmap))
# dev.off()
```

## DGE Analysis 

```{r DGE_analysis, results='asis'}

contrast_list = read.delim("contrasts.tsv",stringsAsFactors = T ,sep='\t')

design = model.matrix(~0 + group, data = meta)

# Loop Through all listed contrasts and run edgeR, GO, GSEAoutput
for (i in 1:length(contrast_list$contrast)){
  myargs = list(paste0(contrast_list[i,1]," = ",
                       "group",contrast_list[i,2], " - ",
                       "group",contrast_list[i,3]),
                       levels=design)
  
  #set values for invocation of edgeR with RNAseq()
  contrast.name = contrast_list[i,1]

  # Divide iterations of this loop in the report.
  cat(paste0("### ",contrast.name), "\n\n")
  
  contrast = do.call(makeContrasts, myargs)
  
  # Do the RNAseq analysis--------------------------------------------------------
  list = RNAseq(
    design = design,
    contrast = contrast,
    .meta <- meta
  )

  # GSEA--------------------------------------------------------------------------
  ## With Reactome
  genesetenrichment(
    de.genelist=list$de.genes, # differential genes
    genelist = t2g_no_dup_genes$ens_gene,
    lengthData = t2g_no_dup_genes$transcript_length,
    goseq_mapper=reactome.mapper.goseq, # reactome gene ontology
    reactome.mapper=reactome.mapper
    # goseq_mapper=dplyr::select(t2g,one_of(c('ens_gene','go_id'))) # To do e.g. BP, CC, MF gene ontology
  )

  ## With GO terms
  genesetenrichment(
    de.genelist=list$de.genes, # differential genes
    genelist = t2g_no_dup_genes$ens_gene,
    lengthData = t2g_no_dup_genes$transcript_length,
    # goseq_mapper=reactome.mapper.goseq, # reactome gene ontology
    goseq_mapper=dplyr::select(t2g,one_of(c('ens_gene','go_id'))) # To do e.g. BP, CC, MF gene ontology
  )

  ## GSEA output
  gsea_output_files(
    file.prefix=contrast.name, # Name the file!
    t2g_no_dup_genes=t2g_no_dup_genes,
    samples = .meta$sample,
    genotypes = .meta$group,
    exprdata = y.voom$E
  )

  # # Save output for intersects:---------------------------------------------------
  # if(!exists("degs.list")){
  #   degs.list=list(list$de.genes)
  #   names(degs.list)=contrast.name
  # }else{
  #   degs.list=list(degs.list,list$de.genes)
  #   names(degs.list)[length(degs.list)]=contrast.name
  # }
  # Write the table: -------------------------------------------------------------
  write.table(list$table, paste0("../deliverables/",contrast.name,".txt"), quote = F, sep = "\t", row.names = F, col.names = T)

  cat("\n\n\n\n")
  
  # # fGSEA: ------------------------------------------------------------------------
  # 
  # # if the analysis has not been run, do it 
  # if (!paste0(contrast.name,"_GSEA.txt") %in% list.files("../deliverables/")){
  #   
  #   pathways_db = c(msigdbr(species = "Homo sapiens", category= "H") %>% 
  #                     split(x = as.character(.$gene_symbol), f = .$gs_name),
  #                   msigdbr(species = "Homo sapiens", category= "C2", subcategory = "CP:KEGG") %>% 
  #                     split(x = as.character(.$gene_symbol), f = .$gs_name))
  #   
  #   cat(paste0("### ",contrast.name), "\n\n")
  #   
  #   # import DGE results for contrast
  #   DGE = read.delim(paste0("../deliverables/",contrast.name, ".txt"), sep = "\t") %>%
  #     select(c("ens_gene","ext_gene","logFC","PValue","FDR"))
  #   
  #   # compute rankings
  #   ranks <- getranks(contrast.name, DGE)
  #   
  #   # do the fgsea analysis
  #   set.seed(1000)
  #   fgseaRes <- fgsea(pathways = pathways_db,
  #                     stats = ranks,
  #                     nperm=1000)
  #   cat("Significant pathways (padj < 0.05):", sum(fgseaRes[, padj < 0.05]), "out of", length(pathways_db),"\n\n")
  #   
  #   # save the results
  #   cat("see",paste0(contrast.name,"_GSEA.txt"),"for table of full GSEA results.")
  #   write.table(fgseaRes %>% select(-c(leadingEdge)), paste0("../deliverables/",contrast.name,"_GSEA.txt"), quote = F, sep = "\t", row.names = F, col.names = T)
  # 
  #   cat("\n\n\n\n")
  # 
  # # if analysis already complete, just provide results file.
  # }else if (paste0(contrast.name,"_GSEA.txt") %in% list.files("../deliverables/")){
  #   cat("see",paste0(contrast.name,"_GSEA.txt"),"for table of full GSEA results.")
  #   cat("\n\n\n\n")
  #   }
} 

```

# Appendix: RNAseq Methods (Continued)

**RNAseq Methods Continued:**

The DGE analysis was performed using the edgeR framework. The TMM normalization for library size and composition bias was applied to the count-filtered data (not the VOOM normalized). This was followed by the models indicated in each contrast tab and tested using the quasi-likelihood F test. P-values were then adjusted using the BH method. Genes were termed significant if they passed the FDR and logFC thresholds (indicated in the specific contrast tabs). These significant genes were used in the gene set enrichment analysis using the R package goseq which adjusts for gene length. Both the Reactome Pathway and Gene Ontologies were tested for enrichment.

**More detailed RNAseq explanation for users**

As a foreward, I want to say that there are many cogs of an RNAseq pipeline that can be substituted with similiar tools and packages with slightly different assumptions. Similarly, different data transformations and models will produce different outcomes. However, in our experience all of these produce similar results and each detects robust findings. We can change any of the models, tools, or features of this pipeline upon request and consultation. Please email me at dean.pettinga@vai.org

Most of the following text describing the RNAseq workflow was copied directly from the following publications to give a summary overview of the workflow:

   * Chen, Y., Lun, A. T. L., & Smyth, G. K. (2016). From reads to genes to pathways: differential expression analysis of RNA-Seq experiments using Rsubread and the edgeR quasi-likelihood pipeline. F1000Research, 5, 1438. https://doi.org/10.12688/f1000research.8987.2.
   * EdgeR User Guide: http://www.bioconductor.org/packages//2.10/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf
   *  Conesa, A., Madrigal, P., Tarazona, S., Gomez-Cabrero, D., Cervera, A., McPherson, A., … Mortazavi, A. (2016). A survey of best practices for RNA-seq data analysis. Genome Biology, 17(1), 13. https://doi.org/10.1186/s13059-016-0881-8
   *  Liu, R., Holik, A. Z., Su, S., Jansz, N., Chen, K., Leong, H. S., … Ritchie, M. E. (2015). Why weight? Modelling sample and observational level variability improves power in RNA-seq analyses. Nucleic Acids Research, 43(15), e97–e97. https://doi.org/10.1093/nar/gkv412

EdgeR uses the negative binomial (NB) distribution to model the read counts for each gene in each sample. The dispersion parameter of the NB distribution accounts for variability between biological replicates. edgeR estimates an empirical Bayes moderated dispersion for each individual gene. It also estimates a common dispersion, which is a global dispersion estimate averaged over all genes, and a trended dispersion where the dispersion of a gene is predicted from its abundance. The estimation is robustified against potential outlier genes. For RNA-seq studies, the NB dispersions tend to be higher for genes with very low counts. The dispersion trend tends to decrease smoothly with abundance and to asymptotic to a constant value for genes with larger counts. From our past experience, the asymptotic value for the BCV tends to be in range from 0.05 to 0.2 for genetically identical mice or cell lines, whereas somewhat larger values (> 0.3) are observed for human subjects.

The NB model can be extended with quasi-likelihood (QL) methods to account for gene-specific variability from both biological and technical sources. Under the QL framework, the NB dispersion trend is used to describe the overall biological variability across all genes, and gene-specific variability above and below the overall level is picked up by the QL dispersion. The raw QL dispersion estimates are squeezed towards a global trend, and this moderation reduces the uncertainty of the estimates and improves testing power. The extent of the squeezing is governed by the value of the prior df estimated from the data. Large prior df estimates indicate that the QL dispersions are less variable between genes, meaning that strong EB moderation should be performed. Smaller prior df estimates indicate that the true unknown dispersions are highly variable, so weaker moderation towards the trend is appropriate. In general, if there are a large number of samples and/or high variability, then the QL dispersions are not squeezed very heavily from the raw values. If there are a low number of samples and/or low variability, then the dispersions will be squeezed more heavily. 

The QL F-test is then used to find differentially expressed genes. While the likelihood ratio test is a more obvious choice for inferences with GLMs, the QL F-test is preferred as it reflects the uncertainty in estimating the dispersion for each gene. It provides more robust and reliable error rate control even when the number of replicates is small.

Gene set enrichment analysis (GSEA) was performed using the Bioconductor package "fGSEA" (Sergushichev A (2016). “An algorithm for fast preranked gene set enrichment analysis using cumulative statistic calculation.” bioRxiv. doi: 10.1101/060012, http://biorxiv.org/content/early/2016/06/20/060012.). This package implements GSEAPreranked in R. 

